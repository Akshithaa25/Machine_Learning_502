{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshithaa25/Machine_Learning_502/blob/main/Akshithaa_502_Lab_4_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYBTsVqBLj2s",
        "outputId": "bc95ef46-b87a-46d9-b2b6-ac3b00e5110f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or2TXQbwVYvA",
        "outputId": "a8d594ab-7f32-4800-f223-03a9cfacf13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag"
      ],
      "metadata": {
        "id": "Qb-iCyVMVdry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bee2b4b-8f0a-4990-db8c-fd496d0280dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p59UPvyOYOdK",
        "outputId": "2314e7af-4116-419f-bd9f-a7d1e1d20eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# synonyms\n",
        "def get_synonyms(word):\n",
        "    synonyms = []\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.append(lemma.name())\n",
        "    return list(set(synonyms))\n",
        "\n",
        "#  3rd meaning of the word\n",
        "def find_third_meaning(word):\n",
        "    synsets = wordnet.synsets(word)\n",
        "    if len(synsets) >= 3:\n",
        "        third_meaning = synsets[2].definition()\n",
        "    else:\n",
        "        third_meaning = \"Not enough meanings found\"\n",
        "    return third_meaning\n",
        "\n",
        "# nouns\n",
        "def extract_nouns(synonyms):\n",
        "    nouns = []\n",
        "    for synonym in synonyms:\n",
        "        tokens = word_tokenize(synonym)\n",
        "        tagged_tokens = pos_tag(tokens)\n",
        "        for token, pos in tagged_tokens:\n",
        "            if pos.startswith('NN'):\n",
        "                nouns.append(token)\n",
        "    return list(set(nouns))\n",
        "\n",
        "# verbs\n",
        "def extract_verbs(synonyms):\n",
        "    verbs = []\n",
        "    for synonym in synonyms:\n",
        "        tokens = word_tokenize(synonym)\n",
        "        tagged_tokens = pos_tag(tokens)\n",
        "        for token, pos in tagged_tokens:\n",
        "            if pos.startswith('VB'):\n",
        "                verbs.append(token)\n",
        "    return list(set(verbs))\n",
        "\n",
        "#  adjectives\n",
        "def extract_adjectives(synonyms):\n",
        "    adjectives = []\n",
        "    for synonym in synonyms:\n",
        "        tokens = word_tokenize(synonym)\n",
        "        tagged_tokens = pos_tag(tokens)\n",
        "        for token, pos in tagged_tokens:\n",
        "            if pos.startswith('JJ'):\n",
        "                adjectives.append(token)\n",
        "    return list(set(adjectives))\n",
        "\n",
        "# adverbs\n",
        "def extract_adverbs(synonyms):\n",
        "    adverbs = []\n",
        "    for synonym in synonyms:\n",
        "        tokens = word_tokenize(synonym)\n",
        "        tagged_tokens = pos_tag(tokens)\n",
        "        for token, pos in tagged_tokens:\n",
        "            if pos.startswith('RB'):\n",
        "                adverbs.append(token)\n",
        "    return list(set(adverbs))\n",
        "\n",
        "#  extract the definition of the word\n",
        "def get_definition(word):\n",
        "    synsets = wordnet.synsets(word)\n",
        "    if synsets:\n",
        "        return synsets[0].definition()\n",
        "    else:\n",
        "        return \"No definition found for the word\"\n",
        "\n",
        "#  hypernyms of the word\n",
        "def get_hypernyms(word):\n",
        "    hypernyms = []\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for hypernym in syn.hypernyms():\n",
        "            hypernyms.append(hypernym.lemma_names()[0])\n",
        "    return list(set(hypernyms))\n",
        "\n",
        "#  find the hyponyms of the word\n",
        "def get_hyponyms(word):\n",
        "    hyponyms = []\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for hyponym in syn.hyponyms():\n",
        "            hyponyms.append(hyponym.lemma_names()[0])\n",
        "    return list(set(hyponyms))\n",
        "\n",
        "#  similarities of any two hyponyms of a word\n",
        "def get_hyponym_similarity(word, hyponym1, hyponym2):\n",
        "    syn1 = wordnet.synsets(word)\n",
        "    syn2 = wordnet.synsets(hyponym1)\n",
        "    syn3 = wordnet.synsets(hyponym2)\n",
        "    if syn1 and syn2 and syn3:\n",
        "        similarity1 = syn1[0].path_similarity(syn2[0])\n",
        "        similarity2 = syn1[0].path_similarity(syn3[0])\n",
        "        return similarity1, similarity2\n",
        "    else:\n",
        "        return \"One or both hyponyms not found\"\n",
        "\n",
        "words = [\"Galaxy\", \"adventure\", \"computer\", \"happiness\", \"Journey\"]\n",
        "\n",
        "\n",
        "for word in words:\n",
        "    synonyms = get_synonyms(word)\n",
        "    print(\"\\nWord:\", word)\n",
        "    print(\"Synonyms:\", synonyms)\n",
        "    print(\"a) 3rd Meaning:\", find_third_meaning(word))\n",
        "    print(\"b) Nouns:\", extract_nouns(synonyms))\n",
        "    print(\"c) Verbs:\", extract_verbs(synonyms))\n",
        "    print(\"d) Adjectives:\", extract_adjectives(synonyms))\n",
        "    print(\"e) Adverbs:\", extract_adverbs(synonyms))\n",
        "    print(\"f) Definition:\", get_definition(word))\n",
        "    print(\"g) Hypernyms:\", get_hypernyms(word))\n",
        "    print(\"h) Hyponyms:\", get_hyponyms(word))\n",
        "    print(\"i) Similarity of Hyponyms:\", get_hyponym_similarity(word, \"hyponym1\", \"hyponym2\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhJFSuLFVwLt",
        "outputId": "a2521736-33b2-4d9d-90d8-f65a1f8ca70d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word: Galaxy\n",
            "Synonyms: ['wandflower', 'extragalactic_nebula', 'Galax_urceolata', 'beetleweed', 'galaxy', 'coltsfoot', 'galax']\n",
            "a) 3rd Meaning: (astronomy) a collection of star systems; any of the billions of systems each having many stars and nebulae and dust\n",
            "b) Nouns: ['wandflower', 'extragalactic_nebula', 'Galax_urceolata', 'beetleweed', 'galaxy', 'coltsfoot', 'galax']\n",
            "c) Verbs: []\n",
            "d) Adjectives: []\n",
            "e) Adverbs: []\n",
            "f) Definition: a splendid assemblage (especially of famous people)\n",
            "g) Hypernyms: ['herb', 'collection']\n",
            "h) Hyponyms: ['Milky_Way', 'Great_Attractor', 'spiral_galaxy']\n",
            "i) Similarity of Hyponyms: One or both hyponyms not found\n",
            "\n",
            "Word: adventure\n",
            "Synonyms: ['hazard', 'take_a_chance', 'dangerous_undertaking', 'risky_venture', 'stake', 'chance', 'run_a_risk', 'jeopardize', 'adventure', 'risk', 'gamble', 'take_chances', 'escapade', 'venture']\n",
            "a) 3rd Meaning: put at risk\n",
            "b) Nouns: ['venture', 'hazard', 'take_a_chance', 'risky_venture', 'chance', 'run_a_risk', 'jeopardize', 'adventure', 'risk', 'gamble', 'take_chances', 'escapade', 'stake']\n",
            "c) Verbs: ['dangerous_undertaking']\n",
            "d) Adjectives: []\n",
            "e) Adverbs: []\n",
            "f) Definition: a wild and exciting undertaking (not necessarily lawful)\n",
            "g) Hypernyms: ['try', 'risk', 'undertaking']\n",
            "h) Hyponyms: ['go_for_broke', 'luck_it']\n",
            "i) Similarity of Hyponyms: One or both hyponyms not found\n",
            "\n",
            "Word: computer\n",
            "Synonyms: ['reckoner', 'computing_machine', 'calculator', 'electronic_computer', 'computing_device', 'information_processing_system', 'estimator', 'computer', 'data_processor', 'figurer']\n",
            "a) 3rd Meaning: Not enough meanings found\n",
            "b) Nouns: ['reckoner', 'computing_machine', 'calculator', 'electronic_computer', 'computing_device', 'information_processing_system', 'estimator', 'computer', 'data_processor', 'figurer']\n",
            "c) Verbs: []\n",
            "d) Adjectives: []\n",
            "e) Adverbs: []\n",
            "f) Definition: a machine for performing calculations automatically\n",
            "g) Hypernyms: ['expert', 'machine']\n",
            "h) Hyponyms: ['Turing_machine', 'predictor', 'home_computer', 'digital_computer', 'web_site', 'adder', 'number_cruncher', 'statistician', 'server', 'pari-mutuel_machine', 'analog_computer', 'node', 'subtracter']\n",
            "i) Similarity of Hyponyms: One or both hyponyms not found\n",
            "\n",
            "Word: happiness\n",
            "Synonyms: ['felicity', 'happiness']\n",
            "a) 3rd Meaning: Not enough meanings found\n",
            "b) Nouns: ['felicity', 'happiness']\n",
            "c) Verbs: []\n",
            "d) Adjectives: []\n",
            "e) Adverbs: []\n",
            "f) Definition: state of well-being characterized by emotions ranging from contentment to intense joy\n",
            "g) Hypernyms: ['emotional_state', 'feeling']\n",
            "h) Hyponyms: ['radiance', 'gaiety', 'rejoicing', 'bonheur', 'cheerfulness', 'belonging', 'blessedness', 'gladness', 'contentment']\n",
            "i) Similarity of Hyponyms: One or both hyponyms not found\n",
            "\n",
            "Word: Journey\n",
            "Synonyms: ['travel', 'journey', 'journeying']\n",
            "a) 3rd Meaning: travel upon or across\n",
            "b) Nouns: ['journey', 'journeying', 'travel']\n",
            "c) Verbs: []\n",
            "d) Adjectives: []\n",
            "e) Adverbs: []\n",
            "f) Definition: the act of traveling from one place to another\n",
            "g) Hypernyms: ['travel']\n",
            "h) Hyponyms: ['tour', 'way', 'sledge', 'trek', 'voyage', 'cruise', 'schlep', 'globe-trot', 'digression', 'trip', 'excursion', 'sail', 'mush', 'drive', 'commute', 'ship', 'ride', 'passage', 'odyssey', 'long_haul', 'fly', 'pilgrimage', 'expedition']\n",
            "i) Similarity of Hyponyms: One or both hyponyms not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n-1o85kTiHE-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}